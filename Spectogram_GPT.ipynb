{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnida/spectogram-gpt-features/blob/main/Spectogram_GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xxStzi9B6WaD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "from typing import List, Optional, Union\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
        "from sae_analysis.visualizer import data_fns, html_fns\n",
        "from sae_analysis.visualizer.data_fns import get_feature_data, FeatureData\n",
        "\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\" \n",
        "else:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "def imshow(x, **kwargs):\n",
        "    x_numpy = utils.to_numpy(x)\n",
        "    px.imshow(x_numpy, **kwargs).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "print(torch.device(device))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSVHP6lffzNB"
      },
      "source": [
        "Our goal here is to create a mel spectrogram type of visualization of GPT-2 Sparse Autoencoder (SAE) different features. The goal is to visualization how features are alike or different.\n",
        "\n",
        "Inspired entirely by @thesephist's tweet: https://x.com/thesephist/status/1754322902210793727?s=20\n",
        "\n",
        "Using the SAE from Joseph Isaac Bloom:\n",
        "https://www.alignmentforum.org/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nagMno06e-b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load in the Sparse Autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aee8f84b38384608a4576e1d4a94e8e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mnida/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60071376c4014e87900128a7055847b2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eedd1a16a16c4bf992f2921b14593622",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aeb16e1b4f3d447faf627a05c67e7c76",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "377a411fa9e34b7cb393906fb7114251",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "579bc35687be4af7ac6b33f7bf8dae60",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n",
            "Moving model to device:  mps\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mnida/miniconda3/envs/mats_sae_training/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cfe0b98e75e416aa3c1bf10def58d6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.73k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f807c51c9ae4fdabbdef22762a0ed79",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/7.33k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset is not tokenized! Updating config.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "path = \"artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_6144:v2/1200001024_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_6144.pt\"\n",
        "model, sparse_autoencoder, activations_loader = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
        "    path\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "xvTbaI7k6fOR",
        "outputId": "904671b9-90c3-4be0-c11c-a78047ae57dc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[1;32m      3\u001b[0m feature_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m  \u001b[38;5;66;03m# Your feature vectors from the autoencoder\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tsne \u001b[38;5;241m=\u001b[39m TSNE(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, perplexity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
          ]
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "feature_vectors = ...  # Your feature vectors from the autoencoder\n",
        "tsne = TSNE(n_components=1, perplexity=30, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(feature_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skdfvQhNoDO3"
      },
      "source": [
        "## Visualize the Spectogram with Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NniR8ydroHtc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Example data\n",
        "times = np.arange(len(tsne_results))  # Assuming each feature vector corresponds to a time token\n",
        "frequencies = tsne_results.flatten()  # Your 1D t-SNE mapped to frequencies\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.scatter(times, frequencies, c=frequencies, cmap='viridis')  # Color by frequency for visualization\n",
        "plt.colorbar(label='Frequency')\n",
        "plt.xlabel('Time (tokens)')\n",
        "plt.ylabel('Frequency (Hz)')\n",
        "plt.title('Spectrogram Representation')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOb2svWdUXcihmI08beYbBX",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
